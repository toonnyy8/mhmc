{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeakerRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SneLHGG2Ii0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import data_table\n",
        "import pandas as pd\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAv1cja_fMkN",
        "colab_type": "text"
      },
      "source": [
        "### 下載資料並進行整理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2GDTyvuQ_6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "84db0edb-bfce-4273-fb2c-38d2b39c736f"
      },
      "source": [
        "!wget https://github.com/toonnyy8/mhmc/raw/master/HW_topic_detection/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-03 14:54:13--  https://github.com/toonnyy8/mhmc/raw/master/HW_topic_detection/data.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/toonnyy8/mhmc/master/HW_topic_detection/data.zip [following]\n",
            "--2020-09-03 14:54:14--  https://raw.githubusercontent.com/toonnyy8/mhmc/master/HW_topic_detection/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2135310 (2.0M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.04M  9.25MB/s    in 0.2s    \n",
            "\n",
            "2020-09-03 14:54:16 (9.25 MB/s) - ‘data.zip’ saved [2135310/2135310]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "   creating: data/test/\n",
            "  inflating: data/test/dialogues_test.txt  \n",
            "  inflating: data/test/dialogues_test_topic.txt  \n",
            "   creating: data/train/\n",
            "  inflating: data/train/dialogues_train.txt  \n",
            "  inflating: data/train/dialogues_train_topic.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1lUYKzxPlvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data_path = './data/train/dialogues_train.txt'\n",
        "training_answer_path = './data/train/dialogues_train_topic.txt'\n",
        "\n",
        "testing_data_path = './data/test/dialogues_test.txt'\n",
        "testing_answer_path = './data/test/dialogues_test_topic.txt'\n",
        "\n",
        "def statis(cm):\n",
        "  accu = 0\n",
        "  for n in range(len(cm)):\n",
        "    accu += cm[n][n]\n",
        "  accu /= sum(sum(cm))\n",
        "  return accu\n",
        "\n",
        "class_weights = np.zeros(10)\n",
        "token_dict = {\"__padding__\":0, \"__cls__\":1, \"__mask__\":3}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1sSdAVoOmdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_txts = open(training_data_path,'r').readlines()\n",
        "train_sentence = []\n",
        "train_max_len = 0\n",
        "for train_txt in train_txts:\n",
        "  sentence = train_txt.replace('\\n','')\n",
        "  sentence_list = sentence.split(' ')\n",
        "  sentence_list = [ch for ch in sentence_list if ch != '']\n",
        "  train_sentence.append(sentence_list)\n",
        "  if len(sentence_list)>train_max_len:\n",
        "    train_max_len = len(sentence_list)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqyfyM-RuiEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_txts = open(testing_data_path,'r').readlines()\n",
        "test_sentence = []\n",
        "test_max_len = 0\n",
        "for test_txt in test_txts:\n",
        "  sentence = test_txt.replace('\\n','')\n",
        "  sentence_list = sentence.split(' ')\n",
        "  sentence_list = [ch for ch in sentence_list if ch != '']\n",
        "  test_sentence.append(sentence_list)\n",
        "  if len(sentence_list)>test_max_len:\n",
        "    test_max_len = len(sentence_list)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8ZsKXhYbQ4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_tokens = np.concatenate([np.ones((len(train_sentence),1),dtype=\"int32\"),np.zeros((len(train_sentence),train_max_len),dtype=\"int32\")],axis=1)\n",
        "train_tokens = np.zeros((len(train_sentence),train_max_len),dtype=\"int32\")\n",
        "\n",
        "for line, sentence_list in enumerate(train_sentence):\n",
        "  for idx, token in enumerate(sentence_list):\n",
        "    if token_dict.get(token) == None:\n",
        "      token_dict[token] = len(token_dict)\n",
        "    train_tokens[line][idx+(train_max_len-len(sentence_list))] = token_dict[token]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITarshJGo_sF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "f0b89747-7aef-421f-92e9-444fcf6f525b"
      },
      "source": [
        "train_tokens"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   4,  26,  14],\n",
              "       [  0,   0,   0, ..., 128,  26,  14],\n",
              "       [  0,   0,   0, ..., 147,  26,  14],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 382,  26,  14],\n",
              "       [  0,   0,   0, ..., 622,  26,  14],\n",
              "       [  0,   0,   0, ...,  29,  26,  14]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NajhlLphepgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_tokens = np.concatenate([np.ones((len(test_sentence),1),dtype=\"int32\"),np.zeros((len(test_sentence),test_max_len),dtype=\"int32\")],axis=1)\n",
        "test_tokens = np.zeros((len(test_sentence),test_max_len),dtype=\"int32\")\n",
        "\n",
        "for line, sentence_list in enumerate(test_sentence):\n",
        "  for idx, token in enumerate(sentence_list):\n",
        "    if token_dict.get(token) == None:\n",
        "      test_tokens[line][idx+(test_max_len-len(sentence_list))] = token_dict[\"__mask__\"]\n",
        "    else:\n",
        "      test_tokens[line][idx+(test_max_len-len(sentence_list))] = token_dict[token]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhnYnRHVMYdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_answers = open(training_answer_path,'r').readlines()\n",
        "train_ans = []\n",
        "for train_answer in train_answers:\n",
        "  train_ans.append(int(train_answer))\n",
        "  class_weights[int(train_answer)-1] += 1\n",
        "\n",
        "class_weights = (np.sum(class_weights)/class_weights)/10"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLYePbbxuzQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_answers = open(testing_answer_path,'r').readlines()\n",
        "test_ans = []\n",
        "for test_answer in test_answers:\n",
        "  test_ans.append(int(test_answer))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4R34Vkdi79k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_masked(inp,rate,mask_id):\n",
        "  return tf.where(\n",
        "    tf.greater_equal(tf.random.uniform(inp.shape,0,1),rate),\n",
        "    inp,\n",
        "    mask_id,\n",
        "  )\n",
        "\n",
        "# random_masked(train_tokens,0.1,token_dict[\"__mask__\"]) "
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucvHC9TspY9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_cls(inp,cls_id):\n",
        "  return tf.concat([tf.ones((inp.shape[0],1),\"int32\"),inp],axis=1)\n",
        "# add_cls(\n",
        "#   random_masked(\n",
        "#     train_tokens,\n",
        "#     0.1,\n",
        "#     token_dict[\"__mask__\"],\n",
        "#   ),\n",
        "#   token_dict[\"__cls__\"]\n",
        "# )"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnaKROzkqg_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "750d91ff-fb15-41c0-c2b1-9c9a1f4a9b1f"
      },
      "source": [
        "# tf.keras.layers.Embedding(len(token_dict), 64)(\n",
        "#   add_cls(\n",
        "#     random_masked(\n",
        "#       train_tokens,\n",
        "#       0.1,\n",
        "#       token_dict[\"__mask__\"],\n",
        "#     ),\n",
        "#     token_dict[\"__cls__\"]\n",
        "#   )   \n",
        "# ).shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10494, 869, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}